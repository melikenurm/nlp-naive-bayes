{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>train</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>train</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>train</td>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>train</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>train</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review label\n",
       "1       test  Once again Mr. Costner has dragged out a movie...   neg\n",
       "2       test  This is an example of why the majority of acti...   neg\n",
       "3       test  First of all I hate those moronic rappers, who...   neg\n",
       "4       test  Not even the Beatles could write songs everyon...   neg\n",
       "5       test  Brass pictures (movies is not a fitting word f...   neg\n",
       "...      ...                                                ...   ...\n",
       "49996  train  Seeing as the vote average was pretty low, and...   pos\n",
       "49997  train  The plot had some wretched, unbelievable twist...   pos\n",
       "49998  train  I am amazed at how this movie(and most others ...   pos\n",
       "49999  train  A Christmas Together actually came before my t...   pos\n",
       "50000  train  Working-class romantic drama from director Mar...   pos\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "lines= csv.reader(open(\"C:\\\\Users\\\\Melike Nur Mermer\\\\imdb_master.csv\"))\n",
    "dataset = list(lines)\n",
    "df=pd.DataFrame(dataset)\n",
    "df=df[1:]\n",
    "df.columns=['index','type','review','label','file']\n",
    "df=df.drop(columns=['index','file'])\n",
    "indexNames = df[(df['label'] == 'unsup')].index\n",
    "df.drop(indexNames , inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Melike Nur\n",
      "[nltk_data]     Mermer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "detokenizer=TreebankWordDetokenizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def text_preprocessing(df, stemming, stop_words_removal):\n",
    "    \n",
    "    df_train=pd.DataFrame(columns=['type','review','label'])\n",
    "    df_test=pd.DataFrame(columns=['type','review','label'])\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        sentence=row.review\n",
    "        typ=row.type\n",
    "        word_tokens = nltk.wordpunct_tokenize(sentence)\n",
    "        word_tokens = [w.lower() for w in word_tokens if w.isalnum()]\n",
    "        \n",
    "        if stop_words_removal==True:\n",
    "            filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        else:\n",
    "            filtered_sentence = word_tokens\n",
    "        \n",
    "        if stemming==True:\n",
    "            stemmed_sentence= []\n",
    "            for w in filtered_sentence:\n",
    "                stemmed_sentence.append(ps.stem(w))\n",
    "        else:\n",
    "            stemmed_sentence = filtered_sentence\n",
    "\n",
    "        row.review=detokenizer.detokenize(stemmed_sentence)\n",
    "        \n",
    "        if typ=='test':\n",
    "            df_test=df_test.append(row)\n",
    "        else:\n",
    "            df_train=df_train.append(row)\n",
    "\n",
    "    df_test=df_test.drop(columns='type')\n",
    "    df_train=df_train.drop(columns='type')\n",
    "    \n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_and_labels(df_train, df_test):\n",
    "    train_data=df_train.review.tolist()\n",
    "    train_labels=df_train.label.tolist()\n",
    "    for i in range(len(train_labels)): \n",
    "        if train_labels[i]=='pos':\n",
    "            train_labels[i]=1\n",
    "        else:\n",
    "            train_labels[i]=0\n",
    "\n",
    "    test_data=df_test.review.tolist()\n",
    "    test_labels=df_test.label.tolist()\n",
    "    for i in range(len(test_labels)): \n",
    "        if test_labels[i]=='pos':\n",
    "            test_labels[i]=1\n",
    "        else:\n",
    "            test_labels[i]=0\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.split(\"\\W+\", text)\n",
    " \n",
    "def get_word_counts(words):\n",
    "    count_word = {}\n",
    "    for word in words:\n",
    "        count_word[word] = count_word.get(word, 0.0) + 1.0\n",
    "    return count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reviews = {}\n",
    "log_class_priors = {}\n",
    "word_counts = {}\n",
    "vocabulary = set()\n",
    "\n",
    "def fit(data, labels):\n",
    "    n = len(labels)\n",
    "    \n",
    "    num_reviews['pos'] = sum(1 for label in labels if label == 1)\n",
    "    num_reviews['neg'] = sum(1 for label in labels if label == 0)\n",
    "    log_class_priors['pos'] = math.log(num_reviews['pos'] / n)\n",
    "    log_class_priors['neg'] = math.log(num_reviews['neg'] / n)\n",
    "    word_counts['pos'] = {}\n",
    "    word_counts['neg'] = {}\n",
    " \n",
    "    for x, y in zip(data, labels):\n",
    "        c = 'pos' if y == 1 else 'neg'\n",
    "        counts = get_word_counts(tokenize(x))\n",
    "        for word, count in counts.items():\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.add(word)\n",
    "            if word not in word_counts[c]:\n",
    "                word_counts[c][word] = 0.0\n",
    " \n",
    "            word_counts[c][word] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    result = []\n",
    "    for x in data:\n",
    "        counts = get_word_counts(tokenize(x))\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for word, _ in counts.items():\n",
    "            if word not in vocabulary: continue\n",
    "            \n",
    "            # add Laplace smoothing\n",
    "            log_w_given_pos = math.log( (word_counts['pos'].get(word, 0.0) + 1) / (num_reviews['pos'] + len(vocabulary)) )\n",
    "            log_w_given_neg = math.log( (word_counts['neg'].get(word, 0.0) + 1) / (num_reviews['neg'] + len(vocabulary)) )\n",
    " \n",
    "            pos_score += log_w_given_pos\n",
    "            neg_score += log_w_given_neg\n",
    " \n",
    "        pos_score += log_class_priors['pos']\n",
    "        neg_score += log_class_priors['neg']\n",
    " \n",
    "        if pos_score > neg_score:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(pred, labels):\n",
    "    pred_pos_label_pos = sum(1 for i in range(len(pred)) if pred[i]==1 and pred[i] == labels[i])\n",
    "    pred_pos_label_neg = sum(1 for i in range(len(pred)) if pred[i]==1 and pred[i] != labels[i])\n",
    "    pred_neg_label_pos = sum(1 for i in range(len(pred)) if pred[i]==0 and pred[i] != labels[i])\n",
    "    pred_neg_label_neg = sum(1 for i in range(len(pred)) if pred[i]==0 and pred[i] == labels[i])\n",
    "    \n",
    "    # TruePositives / (TruePositives + FalsePositives)\n",
    "    precision = pred_pos_label_pos /(pred_pos_label_pos + pred_pos_label_neg)\n",
    "    # TruePositives / (TruePositives + FalseNegatives)\n",
    "    recall = pred_pos_label_pos / (pred_pos_label_pos + pred_neg_label_pos)\n",
    "    # (2 * Precision * Recall) / (Precision + Recall)\n",
    "    return 2*precision*recall / (precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review label\n",
      "25001  story of a man who has unnatural feelings for ...   neg\n",
      "25002  airport 77 starts as a brand new luxury 747 pl...   neg\n",
      "25003  this film lacked something i couldn t put my f...   neg\n",
      "25004  sorry everyone i know this is supposed to be a...   neg\n",
      "25005  when i was little my parents took me along to ...   neg\n",
      "F1-Score without stop-words removal and stemming..:0.8306334035315083\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = text_preprocessing(df, stemming=False, stop_words_removal=False)\n",
    "print(df_train.head())\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = data_and_labels(df_train, df_test)\n",
    "\n",
    "fit(train_data, train_labels)\n",
    "pred = predict(test_data)\n",
    "print(\"F1-Score without stop-words removal and stemming..:\"+str(f1_score(pred, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review label\n",
      "25001  story man unnatural feelings pig starts openin...   neg\n",
      "25002  airport 77 starts brand new luxury 747 plane l...   neg\n",
      "25003  film lacked something put finger first charism...   neg\n",
      "25004  sorry everyone know supposed art film wow hand...   neg\n",
      "25005  little parents took along theater see interior...   neg\n",
      "F1-Score with stop-words removal without stemming..:0.8425412205985778\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = text_preprocessing(df, stemming=False, stop_words_removal=True)\n",
    "print(df_train.head())\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = data_and_labels(df_train, df_test)\n",
    "\n",
    "fit(train_data, train_labels)\n",
    "pred = predict(test_data)\n",
    "print(\"F1-Score with stop-words removal without stemming..:\"+str(f1_score(pred, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review label\n",
      "25001  stori man unnatur feel pig start open scene te...   neg\n",
      "25002  airport 77 start brand new luxuri 747 plane lo...   neg\n",
      "25003  film lack someth put finger first charisma par...   neg\n",
      "25004  sorri everyon know suppos art film wow hand gu...   neg\n",
      "25005  littl parent took along theater see interior o...   neg\n",
      "F1-Score with stop-words removal and stemming..:0.8371175492205932\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = text_preprocessing(df, stemming=True, stop_words_removal=True)\n",
    "print(df_train.head())\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = data_and_labels(df_train, df_test)\n",
    "\n",
    "fit(train_data, train_labels)\n",
    "pred = predict(test_data)\n",
    "print(\"F1-Score with stop-words removal and stemming..:\"+str(f1_score(pred, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
